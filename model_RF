import pandas as pd
import numpy as np
from sklearn.model_selection import GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.utils.class_weight import compute_class_weight
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as imPipeline
import pickle

# Load training data
train_file_path = 'train.xlsx'
train_data = pd.read_excel(train_file_path)

X_train = train_data['text']
y_train = train_data['sentimen']


classes = np.array([0, 1, 2])


class_weights = compute_class_weight('balanced', classes=classes, y=y_train)
class_weight_dict = {i: weight for i, weight in zip(classes, class_weights)}


best_accuracy = 0
desired_accuracy = 0.9  
max_iterations = 10
current_iteration = 0
best_model = None

# Set hyperparameters for tuning
param_grid = {
    'rf__n_estimators': [100, 200, 300],  
    'rf__max_depth': [None, 10, 20],  
    'rf__min_samples_split': [2, 5, 10],  
    'rf__min_samples_leaf': [1, 2, 4]  
}

# Iteratively find the best model
while best_accuracy < desired_accuracy and current_iteration < max_iterations:
    current_iteration += 1
    print(f"Iteration {current_iteration}...")

  
    pipeline = imPipeline([
        ('tfidf', TfidfVectorizer()),  
        ('smote', SMOTE()),  
        ('rf', RandomForestClassifier(class_weight=class_weight_dict))  
    ])

    # Grid Search with cross-validation
    grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=1)
    grid_search.fit(X_train, y_train)

    
    current_best_model = grid_search.best_estimator_

    # Load test data
    test_file_path = 'test.xlsx'
    test_data = pd.read_excel(test_file_path)

    
    X_test = test_data['text']
    y_test = test_data['sentimen']

   
    y_pred = current_best_model.predict(X_test)

    # Calculate accuracy for the current model
    current_accuracy = accuracy_score(y_test, y_pred)
    print(f"Current accuracy: {current_accuracy * 100:.2f}%")

    
    if current_accuracy > best_accuracy:
        best_accuracy = current_accuracy
        best_model = current_best_model
        print(f"New best accuracy found: {best_accuracy * 100:.2f}%")

    # Add a stopping condition if the desired accuracy is reached
    if best_accuracy >= desired_accuracy:
        print(f"Desired accuracy of {desired_accuracy * 100}% reached!")
        break

# Save the best model to 'model.pkl'
with open('model.pkl', 'wb') as f:
    pickle.dump(best_model, f)


test_data['AI_prediction'] = best_model.predict(X_test)


test_data.to_excel('test_with_predictions.xlsx', index=False)

# Calculate and print classification metrics for the best model
print("Classification Report:")
print(classification_report(y_test, test_data['AI_prediction'], target_names=['Negative', 'Positive', 'Neutral']))


accuracy = accuracy_score(y_test, test_data['AI_prediction'])
print(f"Best Accuracy: {accuracy * 100:.2f}%")

conf_matrix = confusion_matrix(y_test, test_data['AI_prediction'])
print("Confusion Matrix:")
print(conf_matrix)
